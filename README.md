# Financial Document Q&A Assistant  
**Internship Assignment — Soothsayer Analytics India Pvt. Ltd.**

---

## Project Overview
This project is a **prototype Financial Document Q&A Assistant** that extracts data from **financial statements** (PDFs or Excel sheets) and allows users to ask **natural language questions** about the content.  

It demonstrates:
- **Document Extraction** → Text, tables, and numbers from financial PDFs/Excels.  
- **Preprocessing & Normalization** → Handles numbers, currencies, missing values, and scanned PDFs (OCR fallback).  
- **Semantic Search (FAISS)** → Breaks documents into chunks and indexes them using embeddings.  
- **Retrieval-Augmented Generation (RAG)** → Uses a local LLM (via Ollama) to answer questions only from the extracted context.  
- **Interactive Frontend** → Built with **Streamlit**, providing upload, preview, and chat features.  

Runs **fully offline** using [Ollama](https://ollama.ai) and open-source models.  
Ready for **financial analysis**, **Q&A**, and **document exploration** tasks.  

---

## Features
- Upload **PDF** or **Excel** financial statements.  
- Extract **raw text**, **tables**, and **line items**.  
- Normalize numbers (₹, $, %, commas, negatives, etc.).  
- Handle scanned PDFs using **OCR (Tesseract)**.  
- Build **vector embeddings** with Sentence-Transformers.  
- Store vectors in **FAISS** for fast retrieval.  
- Ask questions → Answers generated by **Ollama LLM** (e.g., Mistral).  
- Show **sources/chunks** used in the answer.  
- Simple **Streamlit chat interface**.  

---

## Tech Stack
- **Frontend** → Streamlit  
- **Extraction** → pdfplumber, PyMuPDF, Camelot, Tabula, Pandas, Tesseract (OCR fallback)  
- **Vector Search** → FAISS + Sentence-Transformers  
- **LLM Backend** → Ollama (local models like Mistral / Llama2)  
- **Language** → Python 3.9+  

---

## Repository Structure
financial-doc-qa/
├─ app.py # Main Streamlit app
├─ requirements.txt # Dependencies
├─ README.md # Documentation
├─ utils/
│ ├─ extract.py # PDF/Excel parsing + OCR fallback
│ └─ normalize.py # Number normalization utilities
├─ pipeline/
│ ├─ index.py # Embedding + FAISS index build/load
│ ├─ rag.py # Retrieval + Ollama Q&A
│ └─ chunking.py # (future use: advanced chunking)

---

## Setup & Installation

### 1. Clone the repository

git clone https://github.com/<your-username>/financial-doc-qa.git
cd financial-doc-qa

### 2. Create a virtual environment
python -m venv venv

### Activate:
Windows → .\venv\Scripts\activate
Linux/Mac → source venv/bin/activate

### 3. Install dependencies

pip install -r requirements.txt

### 4. Install Tesseract OCR (for scanned PDFs)

Windows → Tesseract installer
Ubuntu/Debian → sudo apt install tesseract-ocr
macOS (brew) → brew install tesseract

### 5. Install Ollama

Download from https://ollama.ai/download

### Then pull a model (Mistral):
ollama pull mistral

### Test:
ollama run mistral

### Running the App
streamlit run app.py
Open in browser → http://localhost:8501

---

## Usage

1. Upload a financial PDF or Excel.
2. The app extracts:
      - Raw text (page by page).
      - Tables (rows & numbers).
      - Builds embeddings & FAISS index.
3. Switch to Chat tab → Ask natural questions like:
      - “What is the total revenue?”
      - “What is net profit margin?”
      - “List all expense categories.”
4. The assistant retrieves context chunks → LLM answers → Sources are shown.

---

## Example Queries

- “What was the company’s total revenue in FY2023?”
- “What is the EBITDA margin?”
- “Compare revenue and expenses year-over-year.”
- “What is the net income trend?”

---

## Troubleshooting

- Camelot error → Requires Ghostscript + Tk.
      -Ubuntu: sudo apt install ghostscript python3-tk
- Tabula error → Requires Java (JDK).
- Ollama not responding → Ensure Ollama app/daemon is running.
- Scanned PDFs not extracted → Check Tesseract is installed and in PATH.
- Slow embeddings → Switch model in pipeline/index.py (e.g., paraphrase-MiniLM-L6-v2).
